{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Grade Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from file:\n",
    "with open('problems.json', 'r') as fp:\n",
    "    problems_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "problem_name     0\n",
       "info             0\n",
       "url              0\n",
       "moves           22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process data\n",
    "df = pd.DataFrame.from_dict(problems_dict, orient = 'index')\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14902"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def move_coordinate(d):\n",
    "    # convert a move to the coorindates of the hold on the board\n",
    "    s_split = re.split('(\\d+)', d['Description'], maxsplit=1)\n",
    "    # extra `-1` in both for 0 indexing\n",
    "    w = ord(s_split[0].upper()) - 64 - 1\n",
    "    h = int(s_split[1]) - 1\n",
    "    \n",
    "    return (h, w, 0)\n",
    "\n",
    "\n",
    "def convert_moves(moves):\n",
    "    array = np.zeros((18, 11, 1))\n",
    "    for move in moves:\n",
    "        array[move_coordinate(move)] = 1\n",
    "    return array\n",
    "\n",
    "\n",
    "df['Moves_array'] = df['moves'].apply(convert_moves)\n",
    "problems = list(df['Moves_array'])\n",
    "len(problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = np.moveaxis(problems, -1, 1)\n",
    "problems = problems.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14902"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process labels\n",
    "grades = []\n",
    "for problem in df['info']:\n",
    "    grades.append(problem[2])\n",
    "    \n",
    "grade_map = {\n",
    "        '5+':0,\n",
    "        '6A': 1,\n",
    "        '6A+': 2,\n",
    "        '6B': 3,\n",
    "        '6B+': 4,\n",
    "        '6C': 5,\n",
    "        '6C+': 6,\n",
    "        '7A': 7,\n",
    "        '7A+': 8,\n",
    "        '7B': 9,\n",
    "        '7B+': 10,\n",
    "        '7C': 11,\n",
    "        '7C+': 12,\n",
    "        '8A': 13,\n",
    "        '8A+': 14,\n",
    "        '8B': 15,\n",
    "        '8B+': 16,\n",
    "        '8C': 17,\n",
    "        '8C+': 18\n",
    "    }\n",
    "\n",
    "grades = [grade.split()[0] for grade in grades]\n",
    "grades = [grade_map[grade] for grade in grades]\n",
    "len(grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProblemDataset(Dataset):\n",
    "    def __init__(self, data, label, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.label = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        image_tensor = torch.from_numpy(image)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        label = self.label[idx]\n",
    "        \n",
    "        \n",
    "        target = torch.tensor(label,dtype=torch.long)\n",
    "        \n",
    "        return image_tensor, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(problems, grades, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ProblemDataset(X_train, y_train)\n",
    "val = ProblemDataset(X_val, y_val)\n",
    "test = ProblemDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queue = DataLoader(train, batch_size=128)\n",
    "val_queue = DataLoader(val, batch_size= 128)\n",
    "test_queue = DataLoader(test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()  # Compulsory operation.\n",
    "        self.conv1 = nn.Conv2d(1, 32, 7, stride=1, padding=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, stride=1, padding=2)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.fc2 = nn.Linear(128, 15)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        # print('after conv1, x.size:', x.size())\n",
    "        x = F.relu(x)  # Functions like ReLU, MaxPooling can be used in forward method as there is no weights in them to store.\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # print('after pool1, x.size:', x.size())\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        # print('after conv2, x.size:', x.size())\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # print('after pool2, x.size:', x.size())\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        # print('after flatten, x.size:', x.size())\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        # print('after fc1, x.size:', x.size())\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        logits = self.fc2(x)\n",
    "        # print('logits.size:', logits.size())\n",
    "        \n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU\n",
      "epoch: 0 step: 200 loss: 2.30 acc: 0.2439\n",
      "epoch: 0 loss: 2.29 acc: 0.2431, val acc: 0.2412\n",
      "epoch: 1 step: 200 loss: 2.18 acc: 0.2603\n",
      "epoch: 1 loss: 2.17 acc: 0.2602, val acc: 0.2700\n",
      "epoch: 2 step: 200 loss: 2.06 acc: 0.2794\n",
      "epoch: 2 loss: 2.05 acc: 0.2797, val acc: 0.2630\n",
      "epoch: 3 step: 200 loss: 1.97 acc: 0.3057\n",
      "epoch: 3 loss: 1.97 acc: 0.3067, val acc: 0.2821\n",
      "epoch: 4 step: 200 loss: 1.91 acc: 0.3125\n",
      "epoch: 4 loss: 1.92 acc: 0.3113, val acc: 0.3009\n",
      "epoch: 5 step: 200 loss: 1.88 acc: 0.3312\n",
      "epoch: 5 loss: 1.88 acc: 0.3275, val acc: 0.2986\n",
      "epoch: 6 step: 200 loss: 1.85 acc: 0.3364\n",
      "epoch: 6 loss: 1.85 acc: 0.3342, val acc: 0.3036\n",
      "epoch: 7 step: 200 loss: 1.82 acc: 0.3424\n",
      "epoch: 7 loss: 1.83 acc: 0.3379, val acc: 0.3113\n",
      "epoch: 8 step: 200 loss: 1.79 acc: 0.3493\n",
      "epoch: 8 loss: 1.80 acc: 0.3462, val acc: 0.3130\n",
      "epoch: 9 step: 200 loss: 1.77 acc: 0.3504\n",
      "epoch: 9 loss: 1.77 acc: 0.3493, val acc: 0.3120\n",
      "epoch: 10 step: 200 loss: 1.75 acc: 0.3574\n",
      "epoch: 10 loss: 1.75 acc: 0.3553, val acc: 0.3160\n",
      "epoch: 11 step: 200 loss: 1.72 acc: 0.3675\n",
      "epoch: 11 loss: 1.72 acc: 0.3650, val acc: 0.3002\n",
      "epoch: 12 step: 200 loss: 1.69 acc: 0.3755\n",
      "epoch: 12 loss: 1.69 acc: 0.3732, val acc: 0.2965\n",
      "epoch: 13 step: 200 loss: 1.67 acc: 0.3675\n",
      "epoch: 13 loss: 1.67 acc: 0.3717, val acc: 0.3069\n",
      "epoch: 14 step: 200 loss: 1.64 acc: 0.3839\n",
      "epoch: 14 loss: 1.64 acc: 0.3863, val acc: 0.3033\n",
      "epoch: 15 step: 200 loss: 1.62 acc: 0.3888\n",
      "epoch: 15 loss: 1.62 acc: 0.3906, val acc: 0.2825\n",
      "epoch: 16 step: 200 loss: 1.59 acc: 0.3980\n",
      "epoch: 16 loss: 1.59 acc: 0.3999, val acc: 0.2861\n",
      "epoch: 17 step: 200 loss: 1.57 acc: 0.3968\n",
      "epoch: 17 loss: 1.57 acc: 0.4006, val acc: 0.2939\n",
      "epoch: 18 step: 200 loss: 1.54 acc: 0.4213\n",
      "epoch: 18 loss: 1.54 acc: 0.4202, val acc: 0.2603\n",
      "epoch: 19 step: 200 loss: 1.52 acc: 0.4176\n",
      "epoch: 19 loss: 1.52 acc: 0.4178, val acc: 0.2999\n",
      "epoch: 20 step: 200 loss: 1.49 acc: 0.4307\n",
      "epoch: 20 loss: 1.49 acc: 0.4291, val acc: 0.2885\n",
      "epoch: 21 step: 200 loss: 1.46 acc: 0.4487\n",
      "epoch: 21 loss: 1.46 acc: 0.4453, val acc: 0.2875\n",
      "epoch: 22 step: 200 loss: 1.45 acc: 0.4488\n",
      "epoch: 22 loss: 1.45 acc: 0.4464, val acc: 0.2902\n",
      "epoch: 23 step: 200 loss: 1.41 acc: 0.4579\n",
      "epoch: 23 loss: 1.42 acc: 0.4562, val acc: 0.2781\n",
      "epoch: 24 step: 200 loss: 1.40 acc: 0.4576\n",
      "epoch: 24 loss: 1.40 acc: 0.4591, val acc: 0.2801\n",
      "epoch: 25 step: 200 loss: 1.37 acc: 0.4646\n",
      "epoch: 25 loss: 1.38 acc: 0.4642, val acc: 0.2674\n",
      "epoch: 26 step: 200 loss: 1.34 acc: 0.4775\n",
      "epoch: 26 loss: 1.34 acc: 0.4781, val acc: 0.2804\n",
      "epoch: 27 step: 200 loss: 1.33 acc: 0.4880\n",
      "epoch: 27 loss: 1.33 acc: 0.4876, val acc: 0.3002\n",
      "epoch: 28 step: 200 loss: 1.30 acc: 0.5093\n",
      "epoch: 28 loss: 1.30 acc: 0.5017, val acc: 0.2710\n",
      "epoch: 29 step: 200 loss: 1.28 acc: 0.5025\n",
      "epoch: 29 loss: 1.29 acc: 0.4998, val acc: 0.2774\n",
      "epoch: 30 step: 200 loss: 1.27 acc: 0.5089\n",
      "epoch: 30 loss: 1.27 acc: 0.5115, val acc: 0.2808\n",
      "epoch: 31 step: 200 loss: 1.24 acc: 0.5243\n",
      "epoch: 31 loss: 1.24 acc: 0.5244, val acc: 0.2825\n",
      "epoch: 32 step: 200 loss: 1.21 acc: 0.5379\n",
      "epoch: 32 loss: 1.21 acc: 0.5374, val acc: 0.2710\n",
      "epoch: 33 step: 200 loss: 1.20 acc: 0.5395\n",
      "epoch: 33 loss: 1.21 acc: 0.5374, val acc: 0.2761\n",
      "epoch: 34 step: 200 loss: 1.19 acc: 0.5493\n",
      "epoch: 34 loss: 1.19 acc: 0.5470, val acc: 0.2788\n",
      "epoch: 35 step: 200 loss: 1.16 acc: 0.5578\n",
      "epoch: 35 loss: 1.16 acc: 0.5570, val acc: 0.2667\n",
      "epoch: 36 step: 200 loss: 1.13 acc: 0.5689\n",
      "epoch: 36 loss: 1.13 acc: 0.5652, val acc: 0.2764\n",
      "epoch: 37 step: 200 loss: 1.11 acc: 0.5849\n",
      "epoch: 37 loss: 1.11 acc: 0.5807, val acc: 0.2761\n",
      "epoch: 38 step: 200 loss: 1.09 acc: 0.5816\n",
      "epoch: 38 loss: 1.10 acc: 0.5804, val acc: 0.2781\n",
      "epoch: 39 step: 200 loss: 1.09 acc: 0.5861\n",
      "epoch: 39 loss: 1.08 acc: 0.5895, val acc: 0.2768\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 40\n",
    "\n",
    "# create a network\n",
    "model = ConvNet()\n",
    "\n",
    "# utilise GPU\n",
    "if torch.cuda.is_available():\n",
    "    print('using GPU')\n",
    "    model = model.to('cuda')\n",
    "else:\n",
    "    print('using CPU')\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), learning_rate)\n",
    "\n",
    "# define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# training\n",
    "## set model to training mode\n",
    "\n",
    "## start training\n",
    "for ep in range(epochs):\n",
    "    ep_loss = 0.0\n",
    "    ep_acc = 0.0\n",
    "    model.train()\n",
    "    for step, (x, y) in enumerate(train_queue):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.to('cuda')\n",
    "            y = y.to('cuda')\n",
    "            \n",
    "        # set gradient to zero        \n",
    "        optimizer.zero_grad()\n",
    "        # calculate output\n",
    "        p = model(x)\n",
    "        _, preds = torch.max(p, 1)\n",
    "        # calculate metrics\n",
    "        loss = criterion(p, y)\n",
    "        acc = torch.sum(preds == y).item()/len(y)\n",
    "        \n",
    "        ep_acc += acc\n",
    "        ep_loss += loss\n",
    "        \n",
    "        # back-prop\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print('\\repoch: %d step: %d loss: %.2f acc: %.4f'\n",
    "                  % (ep, step, ep_loss/(step+1), ep_acc/(step+1)), end='')\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for val_step, (x, y) in enumerate(val_queue):\n",
    "        x = x.to('cuda')\n",
    "        y = y.to('cuda')\n",
    "        p = model(x)\n",
    "        _, preds = torch.max(p, 1)\n",
    "        # calculate metrics\n",
    "        correct += torch.sum(preds == y).item()\n",
    "        \n",
    "    \n",
    "    \n",
    "    print('\\nepoch: %d loss: %.2f acc: %.4f, val acc: %.4f'\n",
    "          % (ep, ep_loss/(step+1), ep_acc/(step+1), correct/len(y_val)))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
